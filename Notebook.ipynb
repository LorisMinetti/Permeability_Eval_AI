{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9606e282a2fd88",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T16:19:44.930275100Z",
     "start_time": "2024-06-21T16:19:43.824631900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Porosity_Tot    SSA_Tot  Conn.Dens.  Porosity     SSA      Ech  \\\n",
      "0          0.205  45.892683     310.913     0.137   5.065  -25.849   \n",
      "1          0.205  45.892683     310.913     0.147   5.253  -31.002   \n",
      "2          0.205  45.892683     310.913     0.131   4.697  -20.047   \n",
      "3          0.176  54.744318     350.137     0.115   5.583  -50.613   \n",
      "4          0.176  54.744318     350.137     0.139   7.447 -136.737   \n",
      "5          0.176  54.744318     350.137     0.115   5.311  -32.907   \n",
      "6          0.184  53.413043     368.141     0.134   6.990 -115.218   \n",
      "7          0.184  53.413043     368.141     0.138   7.132 -110.411   \n",
      "8          0.184  53.413043     368.141     0.116   5.290  -39.748   \n",
      "9          0.020  45.650000      10.573     0.020   0.791   -3.948   \n",
      "10         0.020  45.650000      10.573     0.020   0.806   -2.017   \n",
      "11         0.274  36.324818     458.436     0.273   7.721 -102.424   \n",
      "12         0.274  36.324818     458.436     0.250   6.870  -76.478   \n",
      "13         0.274  36.324818     458.436     0.265   7.560  -95.050   \n",
      "14         0.293  34.412969     607.796     0.250   7.353 -152.126   \n",
      "15         0.293  34.412969     607.796     0.281   8.363 -258.282   \n",
      "16         0.293  34.412969     607.796     0.297   9.123 -362.849   \n",
      "17         0.056  89.214286     303.129     0.075   4.747 -130.705   \n",
      "18         0.056  89.214286     303.129     0.079   5.065 -156.334   \n",
      "19         0.063  79.507937     288.192     0.075   4.747 -130.705   \n",
      "20         0.063  79.507937     288.192     0.079   5.065 -156.334   \n",
      "21         0.066  74.030303     207.810     0.062   4.227 -132.907   \n",
      "22         0.066  74.030303     207.810     0.066   4.532 -162.178   \n",
      "23         0.143  65.230769     397.271     0.151   7.652 -124.943   \n",
      "24         0.143  65.230769     397.271     0.151   7.653 -132.984   \n",
      "25         0.143  65.230769     397.271     0.148   7.510 -121.665   \n",
      "26         0.149  78.543624     307.044     0.136  10.267 -202.056   \n",
      "27         0.149  78.543624     307.044     0.137  10.300 -202.989   \n",
      "28         0.149  78.543624     307.044     0.124   9.292 -160.839   \n",
      "29         0.149  78.543624     307.044     0.136  10.267 -202.056   \n",
      "30         0.149  78.543624     307.044     0.137  10.300 -202.989   \n",
      "31         0.149  78.543624     307.044     0.124   9.292 -160.839   \n",
      "32         0.146  80.671233     286.157     0.098   8.080 -132.730   \n",
      "33         0.146  80.671233     286.157     0.108   8.765 -160.656   \n",
      "34         0.146  80.671233     286.157     0.103   8.463 -161.984   \n",
      "35         0.116  61.767241     116.198     0.104   6.047  -71.467   \n",
      "36         0.116  61.767241     116.198     0.098   5.923  -70.632   \n",
      "37         0.116  61.767241     116.198     0.096   5.808  -68.413   \n",
      "38         0.112  59.857143      95.679     0.092   5.414  -53.370   \n",
      "39         0.112  59.857143      95.679     0.093   5.443  -53.168   \n",
      "40         0.112  59.857143      95.679     0.092   5.425  -53.456   \n",
      "41         0.088  56.443182      68.701     0.077   4.215  -43.860   \n",
      "42         0.088  56.443182      68.701     0.076   4.240  -44.725   \n",
      "43         0.088  56.443182      68.701     0.073   4.035  -39.278   \n",
      "44         0.029  46.724138      17.118     0.026   1.209  -13.631   \n",
      "45         0.050  58.180000      28.320     0.043   2.511  -28.011   \n",
      "46         0.050  58.180000      28.320     0.041   2.340  -18.740   \n",
      "47         0.050  58.180000      28.320     0.042   2.434  -27.463   \n",
      "\n",
      "    Tortuosity          k_m2  \n",
      "0       2.0340  1.473350e-12  \n",
      "1       2.6650  2.254724e-12  \n",
      "2       2.1090  9.543177e-12  \n",
      "3       4.1830  9.664920e-13  \n",
      "4       2.5950  9.180783e-13  \n",
      "5       4.1010  1.435774e-12  \n",
      "6       2.7740  4.010302e-13  \n",
      "7       2.7790  3.937021e-12  \n",
      "8       3.8680  1.933907e-12  \n",
      "9       3.1000  3.021802e-13  \n",
      "10      2.9000  3.190436e-13  \n",
      "11      1.7170  5.516051e-11  \n",
      "12      1.3530  3.822390e-11  \n",
      "13      1.5730  5.275967e-11  \n",
      "14      1.3400  2.009570e-11  \n",
      "15      1.3720  1.319490e-10  \n",
      "16      1.6750  8.289540e-11  \n",
      "17      2.6210  3.390944e-13  \n",
      "18      3.2380  2.066877e-13  \n",
      "19      3.0175  3.390944e-13  \n",
      "20      3.7225  2.066877e-13  \n",
      "21      3.4140  5.531944e-13  \n",
      "22      4.2070  2.456179e-14  \n",
      "23      3.3133  7.811227e-13  \n",
      "24      3.3900  1.235315e-12  \n",
      "25      3.8000  5.429843e-13  \n",
      "26      3.0870  2.933715e-13  \n",
      "27      2.7950  4.255505e-13  \n",
      "28      3.5850  7.133022e-13  \n",
      "29      3.0870  2.933715e-13  \n",
      "30      2.7950  4.255505e-13  \n",
      "31      3.5850  7.133022e-13  \n",
      "32      3.3400  1.767209e-13  \n",
      "33      3.6090  2.211503e-13  \n",
      "34      4.3490  1.739540e-13  \n",
      "35      4.0070  5.697167e-13  \n",
      "36      2.8180  3.235189e-13  \n",
      "37      3.6460  8.485641e-14  \n",
      "38      4.2200  4.966167e-13  \n",
      "39      4.2260  1.459741e-12  \n",
      "40      4.2200  5.462786e-13  \n",
      "41      4.2780  2.564176e-13  \n",
      "42      4.0340  1.021321e-12  \n",
      "43      4.4590  5.362540e-13  \n",
      "44      2.8210  1.924009e-13  \n",
      "45      3.6000  0.000000e+00  \n",
      "46      3.6040  8.750106e-13  \n",
      "47      3.6000  3.461632e-13  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "try:\n",
    "# Carica il tuo file XLSX\n",
    "    xlsx_file = 'dataset/richerDataset.xlsx'  # Sostituisci con il percorso del tuo file\n",
    "\n",
    "# Leggi i dati dal file XLSX e crea un DataFrame\n",
    "    df: DataFrame = pd.read_excel(xlsx_file)\n",
    "\n",
    "# Ora hai un DataFrame con tutti i dati dal tuo file XLSX che puoi utilizzare per l'analisi.\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Il file non è stato trovato.\")\n",
    "# except Exception as e:\n",
    "    print(f\"Si è verificato un errore: {e}\")                                                          \n",
    "    \n",
    "k2_max = df['k_m2'].max()\n",
    "k2_min = df['k_m2'].min()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### voglio rimuoveretutti i valori = 0 della colonna k_m2\n",
    "df = df[df.k_m2 != 0]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lista delle colonne su cui eseguire la data augmentation\n",
    "columns_to_mutate = ['Porosity_Tot', 'SSA_Tot', 'Conn.Dens.', 'Porosity', 'SSA', 'Ech', 'Tortuosity']\n",
    "\n",
    "# Inizializza una lista per conservare i DataFrame mutati\n",
    "dataframes = []\n",
    "\n",
    "# Per ogni colonna, crea una copia del DataFrame con quella colonna impostata a zero\n",
    "for col in columns_to_mutate:\n",
    "    df_mutated = df.copy()\n",
    "    df_mutated[col] = 0\n",
    "    df_mutated['Database'] = col  # Aggiungi una colonna per identificare quale colonna è stata mutata\n",
    "    dataframes.append(df_mutated)\n",
    "\n",
    "# Concatenazione di tutti i DataFrame mutati in uno solo\n",
    "data_augmented = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Se vuoi visualizzare il DataFrame risultante\n",
    "print(data_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf700d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_augmented.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented.drop(['Database'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ad114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#voglio resettare gli indici di df \n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810ed85c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:19:49.355392200Z",
     "start_time": "2024-06-21T16:19:48.890157600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Porosity_Tot    SSA_Tot  Conn.Dens.  Porosity     SSA      Ech  \\\n",
      "0          0.205  45.892683     310.913     0.137   5.065   25.849   \n",
      "1          0.205  45.892683     310.913     0.147   5.253   31.002   \n",
      "2          0.205  45.892683     310.913     0.131   4.697   20.047   \n",
      "3          0.176  54.744318     350.137     0.115   5.583   50.613   \n",
      "4          0.176  54.744318     350.137     0.139   7.447  136.737   \n",
      "5          0.176  54.744318     350.137     0.115   5.311   32.907   \n",
      "6          0.184  53.413043     368.141     0.134   6.990  115.218   \n",
      "7          0.184  53.413043     368.141     0.138   7.132  110.411   \n",
      "8          0.184  53.413043     368.141     0.116   5.290   39.748   \n",
      "9          0.020  45.650000      10.573     0.020   0.791    3.948   \n",
      "10         0.020  45.650000      10.573     0.020   0.806    2.017   \n",
      "11         0.274  36.324818     458.436     0.273   7.721  102.424   \n",
      "12         0.274  36.324818     458.436     0.250   6.870   76.478   \n",
      "13         0.274  36.324818     458.436     0.265   7.560   95.050   \n",
      "14         0.293  34.412969     607.796     0.250   7.353  152.126   \n",
      "15         0.293  34.412969     607.796     0.281   8.363  258.282   \n",
      "16         0.293  34.412969     607.796     0.297   9.123  362.849   \n",
      "17         0.056  89.214286     303.129     0.075   4.747  130.705   \n",
      "18         0.056  89.214286     303.129     0.079   5.065  156.334   \n",
      "19         0.063  79.507937     288.192     0.075   4.747  130.705   \n",
      "20         0.063  79.507937     288.192     0.079   5.065  156.334   \n",
      "21         0.066  74.030303     207.810     0.062   4.227  132.907   \n",
      "22         0.066  74.030303     207.810     0.066   4.532  162.178   \n",
      "23         0.143  65.230769     397.271     0.151   7.652  124.943   \n",
      "24         0.143  65.230769     397.271     0.151   7.653  132.984   \n",
      "25         0.143  65.230769     397.271     0.148   7.510  121.665   \n",
      "26         0.149  78.543624     307.044     0.136  10.267  202.056   \n",
      "27         0.149  78.543624     307.044     0.137  10.300  202.989   \n",
      "28         0.149  78.543624     307.044     0.124   9.292  160.839   \n",
      "29         0.149  78.543624     307.044     0.136  10.267  202.056   \n",
      "30         0.149  78.543624     307.044     0.137  10.300  202.989   \n",
      "31         0.149  78.543624     307.044     0.124   9.292  160.839   \n",
      "32         0.146  80.671233     286.157     0.098   8.080  132.730   \n",
      "33         0.146  80.671233     286.157     0.108   8.765  160.656   \n",
      "34         0.146  80.671233     286.157     0.103   8.463  161.984   \n",
      "35         0.116  61.767241     116.198     0.104   6.047   71.467   \n",
      "36         0.116  61.767241     116.198     0.098   5.923   70.632   \n",
      "37         0.116  61.767241     116.198     0.096   5.808   68.413   \n",
      "38         0.112  59.857143      95.679     0.092   5.414   53.370   \n",
      "39         0.112  59.857143      95.679     0.093   5.443   53.168   \n",
      "40         0.112  59.857143      95.679     0.092   5.425   53.456   \n",
      "41         0.088  56.443182      68.701     0.077   4.215   43.860   \n",
      "42         0.088  56.443182      68.701     0.076   4.240   44.725   \n",
      "43         0.088  56.443182      68.701     0.073   4.035   39.278   \n",
      "44         0.029  46.724138      17.118     0.026   1.209   13.631   \n",
      "45         0.050  58.180000      28.320     0.043   2.511   28.011   \n",
      "46         0.050  58.180000      28.320     0.041   2.340   18.740   \n",
      "47         0.050  58.180000      28.320     0.042   2.434   27.463   \n",
      "\n",
      "    Tortuosity          k_m2  \n",
      "0       2.0340  1.473350e-12  \n",
      "1       2.6650  2.254724e-12  \n",
      "2       2.1090  9.543177e-12  \n",
      "3       4.1830  9.664920e-13  \n",
      "4       2.5950  9.180783e-13  \n",
      "5       4.1010  1.435774e-12  \n",
      "6       2.7740  4.010302e-13  \n",
      "7       2.7790  3.937021e-12  \n",
      "8       3.8680  1.933907e-12  \n",
      "9       3.1000  3.021802e-13  \n",
      "10      2.9000  3.190436e-13  \n",
      "11      1.7170  5.516051e-11  \n",
      "12      1.3530  3.822390e-11  \n",
      "13      1.5730  5.275967e-11  \n",
      "14      1.3400  2.009570e-11  \n",
      "15      1.3720  1.319490e-10  \n",
      "16      1.6750  8.289540e-11  \n",
      "17      2.6210  3.390944e-13  \n",
      "18      3.2380  2.066877e-13  \n",
      "19      3.0175  3.390944e-13  \n",
      "20      3.7225  2.066877e-13  \n",
      "21      3.4140  5.531944e-13  \n",
      "22      4.2070  2.456179e-14  \n",
      "23      3.3133  7.811227e-13  \n",
      "24      3.3900  1.235315e-12  \n",
      "25      3.8000  5.429843e-13  \n",
      "26      3.0870  2.933715e-13  \n",
      "27      2.7950  4.255505e-13  \n",
      "28      3.5850  7.133022e-13  \n",
      "29      3.0870  2.933715e-13  \n",
      "30      2.7950  4.255505e-13  \n",
      "31      3.5850  7.133022e-13  \n",
      "32      3.3400  1.767209e-13  \n",
      "33      3.6090  2.211503e-13  \n",
      "34      4.3490  1.739540e-13  \n",
      "35      4.0070  5.697167e-13  \n",
      "36      2.8180  3.235189e-13  \n",
      "37      3.6460  8.485641e-14  \n",
      "38      4.2200  4.966167e-13  \n",
      "39      4.2260  1.459741e-12  \n",
      "40      4.2200  5.462786e-13  \n",
      "41      4.2780  2.564176e-13  \n",
      "42      4.0340  1.021321e-12  \n",
      "43      4.4590  5.362540e-13  \n",
      "44      2.8210  1.924009e-13  \n",
      "45      3.6000  0.000000e+00  \n",
      "46      3.6040  8.750106e-13  \n",
      "47      3.6000  3.461632e-13  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Standardizza i dati con lo scaler\n",
    "scaler = MinMaxScaler()  \n",
    "df['Ech'] = -df['Ech']  # Trasforma tutti i valori della colonna Ech in positivi\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d946c779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:25:08.044871300Z",
     "start_time": "2024-06-21T16:25:07.587119800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame scalato:\n",
      "    Porosity_Tot   SSA_Tot  Conn.Dens.  Porosity       SSA       Ech  \\\n",
      "0       0.702796  0.300268    0.831241  0.451988  0.662183  0.456124   \n",
      "1       0.702796  0.300268    0.831241  0.488435  0.678756  0.492759   \n",
      "2       0.702796  0.300268    0.831241  0.429965  0.628202  0.405322   \n",
      "3       0.600079  0.485181    0.861132  0.370661  0.706675  0.592493   \n",
      "4       0.600079  0.485181    0.861132  0.459303  0.842027  0.797309   \n",
      "5       0.600079  0.485181    0.861132  0.370661  0.683768  0.504824   \n",
      "6       0.628666  0.459332    0.873750  0.440991  0.811831  0.761862   \n",
      "7       0.628666  0.459332    0.873750  0.455647  0.821395  0.753048   \n",
      "8       0.628666  0.459332    0.873750  0.374392  0.681958  0.543173   \n",
      "9       0.000000  0.294719    0.000000  0.000000  0.000000  0.103229   \n",
      "10      0.000000  0.294719    0.000000  0.000000  0.004528  0.000000   \n",
      "11      0.937581  0.056229    0.928969  0.922258  0.859357  0.737526   \n",
      "12      0.937581  0.056229    0.928969  0.846368  0.803616  0.677256   \n",
      "13      0.937581  0.056229    0.928969  0.896018  0.849241  0.722091   \n",
      "14      1.000000  0.000000    1.000000  0.846368  0.835952  0.819409   \n",
      "15      1.000000  0.000000    1.000000  0.948334  0.897919  0.929301   \n",
      "16      1.000000  0.000000    1.000000  1.000000  0.940287  1.000000   \n",
      "17      0.146252  1.000000    0.824864  0.218596  0.632946  0.787965   \n",
      "18      0.146252  1.000000    0.824864  0.234055  0.662183  0.825066   \n",
      "19      0.174110  0.878269    0.812155  0.218596  0.632946  0.787965   \n",
      "20      0.174110  0.878269    0.812155  0.234055  0.662183  0.825066   \n",
      "21      0.185994  0.802915    0.729975  0.167955  0.581459  0.791424   \n",
      "22      0.185994  0.802915    0.729975  0.183602  0.612246  0.832676   \n",
      "23      0.480066  0.669512    0.892917  0.502926  0.855044  0.778630   \n",
      "24      0.480066  0.669512    0.892917  0.502926  0.855107  0.791544   \n",
      "25      0.480066  0.669512    0.892917  0.492063  0.846061  0.773127   \n",
      "26      0.502143  0.865382    0.828091  0.448325  0.998412  0.878297   \n",
      "27      0.502143  0.865382    0.828091  0.451988  1.000000  0.879254   \n",
      "28      0.502143  0.865382    0.828091  0.404123  0.949276  0.830956   \n",
      "29      0.502143  0.865382    0.828091  0.448325  0.998412  0.878297   \n",
      "30      0.502143  0.865382    0.828091  0.451988  1.000000  0.879254   \n",
      "31      0.502143  0.865382    0.828091  0.404123  0.949276  0.830956   \n",
      "32      0.491119  0.893610    0.810373  0.306711  0.881257  0.791148   \n",
      "33      0.491119  0.893610    0.810373  0.344448  0.920741  0.830720   \n",
      "34      0.491119  0.893610    0.810373  0.325622  0.903686  0.832428   \n",
      "35      0.379268  0.612073    0.584230  0.329394  0.743652  0.663304   \n",
      "36      0.379268  0.612073    0.584230  0.306711  0.734014  0.660886   \n",
      "37      0.379268  0.612073    0.584230  0.299122  0.724920  0.654320   \n",
      "38      0.364128  0.579024    0.535661  0.283904  0.692557  0.603352   \n",
      "39      0.364128  0.579024    0.535661  0.287714  0.695006  0.602575   \n",
      "40      0.364128  0.579024    0.535661  0.283904  0.693487  0.603682   \n",
      "41      0.272128  0.517285    0.453098  0.226333  0.580211  0.563234   \n",
      "42      0.272128  0.517285    0.453098  0.222466  0.582807  0.567219   \n",
      "43      0.272128  0.517285    0.453098  0.210845  0.561142  0.540752   \n",
      "44      0.037041  0.319063    0.113109  0.024412  0.113878  0.329450   \n",
      "45      0.122226  0.549139    0.234580  0.092813  0.365427  0.472284   \n",
      "46      0.122226  0.549139    0.234580  0.084824  0.338321  0.391944   \n",
      "47      0.122226  0.549139    0.234580  0.088821  0.353388  0.468305   \n",
      "\n",
      "    Tortuosity      k_m2  \n",
      "0     0.306607  0.011166  \n",
      "1     0.529654  0.017088  \n",
      "2     0.335433  0.072325  \n",
      "3     0.938755  0.007325  \n",
      "4     0.506889  0.006958  \n",
      "5     0.919929  0.010881  \n",
      "6     0.564250  0.003039  \n",
      "7     0.565813  0.029837  \n",
      "8     0.864738  0.014656  \n",
      "9     0.662054  0.002290  \n",
      "10    0.603018  0.002418  \n",
      "11    0.176337  0.418044  \n",
      "12    0.006540  0.289687  \n",
      "13    0.112053  0.399849  \n",
      "14    0.000000  0.152299  \n",
      "15    0.016034  1.000000  \n",
      "16    0.157946  0.628238  \n",
      "17    0.515396  0.002570  \n",
      "18    0.701134  0.001566  \n",
      "19    0.638059  0.002570  \n",
      "20    0.828917  0.001566  \n",
      "21    0.749167  0.004192  \n",
      "22    0.944209  0.000186  \n",
      "23    0.721924  0.005920  \n",
      "24    0.742731  0.009362  \n",
      "25    0.848132  0.004115  \n",
      "26    0.658306  0.002223  \n",
      "27    0.570800  0.003225  \n",
      "28    0.794036  0.005406  \n",
      "29    0.658306  0.002223  \n",
      "30    0.570800  0.003225  \n",
      "31    0.794036  0.005406  \n",
      "32    0.729209  0.001339  \n",
      "33    0.800199  0.001676  \n",
      "34    0.975970  0.001318  \n",
      "35    0.897973  0.004318  \n",
      "36    0.577933  0.002452  \n",
      "37    0.809637  0.000643  \n",
      "38    0.947152  0.003764  \n",
      "39    0.948508  0.011063  \n",
      "40    0.947152  0.004140  \n",
      "41    0.960196  0.001943  \n",
      "42    0.904321  0.007740  \n",
      "43    1.000000  0.004064  \n",
      "44    0.578861  0.001458  \n",
      "45    0.797891  0.000000  \n",
      "46    0.798917  0.006631  \n",
      "47    0.797891  0.002623  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Seleziona le colonne da scalare (tutte eccetto 'k_m2')\n",
    "#columns_to_scale = df.columns.difference(['k_m2'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Standardizza solo le colonne selezionate\n",
    "#scaled_data = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "\n",
    "logged_df = df.apply(np.log1p)\n",
    "scaler.fit(logged_df)\n",
    "scaled_data = scaler.fit_transform(logged_df)\n",
    "# Crea un nuovo DataFrame con i dati scalati e riassegna le colonne non scalate\n",
    "#df_scaled = pd.DataFrame(scaled_data, columns=columns_to_scale)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "# Riaggiungi la colonna 'k_m2' al DataFrame scalato\n",
    "#df_scaled['k_m2'] = df['k_m2']\n",
    "\n",
    "# Stampa il DataFrame scalato\n",
    "print(\"DataFrame scalato:\")\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9bfa7c",
   "metadata": {},
   "source": [
    "Viene testato ogni possibile estimatore per trovare il migliore in base al miglior \n",
    "random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eca1c91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:26:07.790049700Z",
     "start_time": "2024-06-21T16:25:27.816833700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Algorithms: 100%|██████████| 9/9 [00:33<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valutazione completata e risultati salvati in 'risultati_alle_mod_K.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "#Snippet per comprendere quale modello è più performante con i miei dati\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suddivisione del dataset in set di addestramento e test\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "X = df_scaled.drop('k_m2', axis=1)\n",
    "y = df_scaled['k_m2']\n",
    "\n",
    "# Lista degli algoritmi da testare\n",
    "algorithms = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Ridge Regression\", Ridge()),\n",
    "    (\"Lasso Regression\", Lasso()),\n",
    "    (\"Decision Tree Regressor\", DecisionTreeRegressor()),\n",
    "    (\"Random Forest Regressor\", RandomForestRegressor()),\n",
    "    (\"SVR\", SVR()),\n",
    "    (\"Gaussian Process Regressor\", GaussianProcessRegressor()),\n",
    "    (\"MLP Regressor\", MLPRegressor(max_iter=1000)),\n",
    "    (\"XGBoost Regressor\", XGBRegressor())\n",
    "]\n",
    "\n",
    "# Definisci un dizionario per raccogliere i risultati\n",
    "results_dict = {\n",
    "    \"Model\": [],\n",
    "    \"Random State\": [],\n",
    "    \"Training RMSE\": [],\n",
    "    \"Training MSE\": [],\n",
    "    \"Training R^2\": [],\n",
    "    \"Test RMSE\": [],\n",
    "    \"Test MSE\": [],\n",
    "    \"Test R^2\": [],\n",
    "    \"Training Time (s)\": []\n",
    "}\n",
    "\n",
    "# Ciclo attraverso gli algoritmi e i random_state\n",
    "for name, model in tqdm(algorithms, desc=\"Testing Algorithms\"):\n",
    "    best_r2 = -float('inf')\n",
    "    best_random_state = None\n",
    "    best_train_rmse = None\n",
    "    best_train_mse = None\n",
    "    best_train_r2 = None\n",
    "    best_test_rmse = None\n",
    "    best_test_mse = None\n",
    "    best_test_r2 = None\n",
    "    best_training_time = None\n",
    "\n",
    "    for random_state in range(1, 101):\n",
    "        # Suddivisione del dataset in set di addestramento e test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "        # Misura il tempo di inizio dell'allenamento\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Addestramento del modello\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcola il tempo di fine dell'allenamento\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calcola il tempo totale di addestramento\n",
    "        training_time = end_time - start_time   \n",
    "\n",
    "        # Valutazione del modello sui dati di addestramento\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        rmse_train = np.sqrt(mse_train)\n",
    "        r2_train = model.score(X_train, y_train)\n",
    "\n",
    "        # Valutazione del modello sui dati di test\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = model.score(X_test, y_test)\n",
    "\n",
    "        # Aggiorna i risultati se l'R^2 sui dati di test è migliorato\n",
    "        if r2_test > best_r2:\n",
    "            best_r2 = r2_test\n",
    "            best_random_state = random_state\n",
    "            best_train_rmse = rmse_train\n",
    "            best_train_mse = mse_train\n",
    "            best_train_r2 = r2_train\n",
    "            best_test_rmse = rmse_test\n",
    "            best_test_mse = mse_test\n",
    "            best_test_r2 = r2_test\n",
    "            best_training_time = training_time\n",
    "\n",
    "    # Aggiungi i risultati migliori per ogni modello al dizionario\n",
    "    results_dict[\"Model\"].append(name)\n",
    "    results_dict[\"Random State\"].append(best_random_state)\n",
    "    results_dict[\"Training RMSE\"].append(best_train_rmse)\n",
    "    results_dict[\"Training MSE\"].append(best_train_mse)\n",
    "    results_dict[\"Training R^2\"].append(best_train_r2)\n",
    "    results_dict[\"Test RMSE\"].append(best_test_rmse)\n",
    "    results_dict[\"Test MSE\"].append(best_test_mse)\n",
    "    results_dict[\"Test R^2\"].append(best_test_r2)\n",
    "    results_dict[\"Training Time (s)\"].append(best_training_time)\n",
    "\n",
    "# Crea un DataFrame da results_dict\n",
    "risultati_alle_mod_K = pd.DataFrame(results_dict)\n",
    "\n",
    "# Esporta il DataFrame in un file Excel\n",
    "risultati_alle_mod_K.to_excel('risultati_alle_mod_K.xlsx', index=False)\n",
    "\n",
    "print(\"Valutazione completata e risultati salvati in 'risultati_alle_mod_K.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbd17ec9abb9e7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Snippet per comprendere quale modello è più performante con i miei dati\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suddivisione del dataset in set di addestramento e test\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Fissare il seed per la riproducibilità\n",
    "#np.random.seed(37)\n",
    "\n",
    "# In questo esempio, consideriamo k sia la colonna target\n",
    "features_X = df_scaled.drop(['k_m2'], axis=1)  # Colonne features\n",
    "targets_X = df_scaled[['k_m2']]  # Colonne target\n",
    "\n",
    "# Suddivisione del dataset in set di addestramento e test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_X, targets_X, test_size=0.2, random_state=37)\n",
    "\n",
    "# Lista degli algoritmi da testare\n",
    "algorithms = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Ridge Regression\", Ridge()),\n",
    "    (\"Lasso Regression\", Lasso()),\n",
    "    (\"Decision Tree Regressor\", DecisionTreeRegressor()),\n",
    "    (\"Random Forest Regressor\", RandomForestRegressor()),\n",
    "    (\"SVR\", SVR()),\n",
    "    (\"Gaussian Process Regressor\", GaussianProcessRegressor()),\n",
    "    (\"MLP Regressor\", MLPRegressor()),\n",
    "    (\"XGBoost Regressor\", XGBRegressor()),\n",
    "]\n",
    "\n",
    "# Definisci un dizionario per raccogliere i risultati\n",
    "results_dict = {\n",
    "    \"Model\": [],\n",
    "    \"Training RMSE\": [],\n",
    "    \"Training MSE\": [],\n",
    "    \"Training R^2\": [],\n",
    "    \"Test RMSE\": [],\n",
    "    \"Test MSE\": [],\n",
    "    \"Test R^2\": [],\n",
    "    \"Training Time (s)\": []\n",
    "}\n",
    "\n",
    "# Ciclo attraverso gli algoritmi e addestra/valuta ciascuno\n",
    "for name, model in tqdm(algorithms, desc=\"Testing Algorithms\"):\n",
    "    \n",
    "    # Misura il tempo di inizio dell'allenamento\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Addestramento del modello\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calcola il tempo di fine dell'allenamento\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calcola il tempo totale di addestramento\n",
    "    training_time = end_time - start_time   \n",
    "\n",
    "    # Valutazione del modello sui dati di addestramento\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    r2_train = model.score(X_train, y_train)\n",
    "\n",
    "    # Valutazione del modello sui dati di test\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    r2_test = model.score(X_test, y_test)\n",
    "\n",
    "    # Aggiungi i risultati al dizionario\n",
    "    results_dict[\"Model\"].append(name)\n",
    "    results_dict[\"Training RMSE\"].append(rmse_train)\n",
    "    results_dict[\"Training MSE\"].append(mse_train)\n",
    "    results_dict[\"Training R^2\"].append(r2_train)\n",
    "    results_dict[\"Test RMSE\"].append(rmse_test)\n",
    "    results_dict[\"Test MSE\"].append(mse_test)\n",
    "    results_dict[\"Test R^2\"].append(r2_test)\n",
    "    results_dict[\"Training Time (s)\"].append(training_time)\n",
    "\n",
    "# Crea un DataFrame da results_dict\n",
    "risultati_alle_mod_K = pd.DataFrame(results_dict)\n",
    "# Esporta il DataFrame in un file Excel\n",
    "risultati_alle_mod_K.to_excel('risultati_alle_mod_K.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b23f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42ee85d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T16:32:12.134769800Z",
     "start_time": "2024-06-21T16:31:57.653196200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State 1: R^2 = 0.2113264882384469\n",
      "Random State 2: R^2 = 0.41820566565490447\n",
      "Random State 3: R^2 = 0.994883944163197\n",
      "Random State 4: R^2 = 0.9646792993703379\n",
      "Random State 5: R^2 = 0.46785841771451275\n",
      "Random State 6: R^2 = -9.144299759351052\n",
      "Random State 7: R^2 = 0.681049319009253\n",
      "Random State 8: R^2 = 0.962567707257277\n",
      "Random State 9: R^2 = 0.6650458081493531\n",
      "Random State 10: R^2 = 0.2759672374796225\n",
      "Random State 11: R^2 = -8.610649708795606\n",
      "Random State 12: R^2 = -0.07338669757175631\n",
      "Random State 13: R^2 = -9.932081246211606\n",
      "Random State 14: R^2 = -8.937717586246103\n",
      "Random State 15: R^2 = 0.4392622268034023\n",
      "Random State 16: R^2 = -0.5229158209195941\n",
      "Random State 17: R^2 = 0.9244175470184514\n",
      "Random State 18: R^2 = 0.9626245772975178\n",
      "Random State 19: R^2 = 0.9852283487683094\n",
      "Random State 20: R^2 = 0.9872534758511256\n",
      "Random State 21: R^2 = -8.119326234878306\n",
      "Random State 22: R^2 = 0.9941455752508012\n",
      "Random State 23: R^2 = -0.5736534951890866\n",
      "Random State 24: R^2 = 0.9671074162920721\n",
      "Random State 25: R^2 = -7.944038582561378\n",
      "Random State 26: R^2 = -8.830418469327768\n",
      "Random State 27: R^2 = 0.9697663165076461\n",
      "Random State 28: R^2 = 0.9621365243293658\n",
      "Random State 29: R^2 = -3.0346562527127174\n",
      "Random State 30: R^2 = -0.511624848799201\n",
      "Random State 31: R^2 = -0.656029043649107\n",
      "Random State 32: R^2 = 0.9678824205854656\n",
      "Random State 33: R^2 = 0.7142628020139314\n",
      "Random State 34: R^2 = 0.9418413619065571\n",
      "Random State 35: R^2 = -11.498597522604943\n",
      "Random State 36: R^2 = 0.9695961980017517\n",
      "Random State 37: R^2 = 0.923106196557342\n",
      "Random State 38: R^2 = -21.517498830978735\n",
      "Random State 39: R^2 = 0.9166843765955177\n",
      "Random State 40: R^2 = 0.9802381329141066\n",
      "Random State 41: R^2 = -9.227234996860151\n",
      "Random State 42: R^2 = 0.992848406524005\n",
      "Random State 43: R^2 = -0.23758207344324256\n",
      "Random State 44: R^2 = -3.473553363177965\n",
      "Random State 45: R^2 = 0.9685578185781725\n",
      "Random State 46: R^2 = -0.19671614076587818\n",
      "Random State 47: R^2 = 0.9953528961785005\n",
      "Random State 48: R^2 = -0.19642343367134973\n",
      "Random State 49: R^2 = -10.184668815315892\n",
      "Random State 50: R^2 = 0.9830308573113742\n",
      "Random State 51: R^2 = 0.6817695426104946\n",
      "Random State 52: R^2 = -3.952167355384355\n",
      "Random State 53: R^2 = 0.3428968946359632\n",
      "Random State 54: R^2 = -10.073615110704324\n",
      "Random State 55: R^2 = 0.2864089070781871\n",
      "Random State 56: R^2 = 0.07441083707954665\n",
      "Random State 57: R^2 = 0.9462311939258531\n",
      "Random State 58: R^2 = -1.1329544421215134\n",
      "Random State 59: R^2 = 0.9510010693135357\n",
      "Random State 60: R^2 = 0.9664330776206823\n",
      "Random State 61: R^2 = 0.9936529149331819\n",
      "Random State 62: R^2 = 0.45898790736271144\n",
      "Random State 63: R^2 = 0.4380795025822902\n",
      "Random State 64: R^2 = 0.1997123965369345\n",
      "Random State 65: R^2 = -11.016709752141491\n",
      "Random State 66: R^2 = -8.634480813813065\n",
      "Random State 67: R^2 = 0.43838176503144344\n",
      "Random State 68: R^2 = 0.13073057211922656\n",
      "Random State 69: R^2 = 0.2623296924231443\n",
      "Random State 70: R^2 = 0.9394901796029503\n",
      "Random State 71: R^2 = -1.9300279420922895\n",
      "Random State 72: R^2 = 0.9241114349881365\n",
      "Random State 73: R^2 = 0.9853745587289079\n",
      "Random State 74: R^2 = 0.9867983153076318\n",
      "Random State 75: R^2 = 0.6538999686720541\n",
      "Random State 76: R^2 = -9.67358097883429\n",
      "Random State 77: R^2 = 0.9722491970407474\n",
      "Random State 78: R^2 = 0.6401229796280854\n",
      "Random State 79: R^2 = -7.3623539752334235\n",
      "Random State 80: R^2 = 0.9986482228176822\n",
      "Random State 81: R^2 = -9.207076668379957\n",
      "Random State 82: R^2 = 0.9242154746322458\n",
      "Random State 83: R^2 = 0.9832919014284568\n",
      "Random State 84: R^2 = 0.9953692045892483\n",
      "Random State 85: R^2 = -13.498038316043612\n",
      "Random State 86: R^2 = 0.6474413340046747\n",
      "Random State 87: R^2 = 0.9615753329057415\n",
      "Random State 88: R^2 = 0.38860370943177724\n",
      "Random State 89: R^2 = 0.5775211487471412\n",
      "Random State 90: R^2 = -0.4492583295048238\n",
      "Random State 91: R^2 = 0.9752072744555275\n",
      "Random State 92: R^2 = 0.6563357216716375\n",
      "Random State 93: R^2 = -0.8559227313743916\n",
      "Random State 94: R^2 = 0.9969967658504877\n",
      "Random State 95: R^2 = 0.952456149246447\n",
      "Random State 96: R^2 = 0.9530084214167605\n",
      "Random State 97: R^2 = 0.9599023482473518\n",
      "Random State 98: R^2 = -7.023310088378871\n",
      "Random State 99: R^2 = 0.9367726246714464\n",
      "Random State 100: R^2 = -4.77980940166263\n",
      "\n",
      "Miglior R^2 trovato: 0.9986482228176822 con Random State: 80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Definire i dati\n",
    "# Supponiamo che X e y siano già definiti correttamente come feature matrix e target vector rispettivamente\n",
    "\n",
    "# Inizializza i migliori valori di R^2 e random_state\n",
    "best_r2 = float('-inf')\n",
    "best_random_state = None\n",
    "best_index = None\n",
    "\n",
    "# Ciclo attraverso tutti i possibili random_state da 1 a 100\n",
    "for random_state in range(1, 101):\n",
    "    # Dividi i dati in training e test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Inizializza il regressore con il random_state corrente\n",
    "    regressor = XGBRegressor(random_state=random_state)\n",
    "    \n",
    "    # Addestramento del regressore\n",
    "    regressor.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # Previsioni e valutazione del modello\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Stampare il R^2 per ogni random_state (opzionale)\n",
    "    print(f\"Random State {random_state}: R^2 = {r2}\")\n",
    "    \n",
    "    # Aggiornamento del miglior R^2 e del random_state associato\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_random_state = random_state\n",
    "        best_index = regressor\n",
    "\n",
    "# Stampare il miglior R^2 e il random_state associato\n",
    "print(f\"\\nMiglior R^2 trovato: {best_r2} con Random State: {best_random_state}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf36eff9123c949",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ora possiamo effettuare il primo allenamento grezzo con l'estimator che ha dato i risultati migliori\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "regressor =  XGBRegressor( random_state = best_random_state )\n",
    "\n",
    "regressor.fit(X_train, y_train.values.ravel())\n",
    "predict_k = regressor.predict(X_test)\n",
    "print(f\"R 2 : {regressor.score(X_test, y_test)}\" )\n",
    "mse_k = mean_squared_error(y_test, predict_k)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"MSE: {mse_k}\")\n",
    "\n",
    "# Calcola il Mean Absolute Error (MAE)\n",
    "mae_k = mean_absolute_error(y_test, predict_k)\n",
    "print(f\"MAE: {mae_k}\")\n",
    "\n",
    "# Calcola il Root Mean Squared Error (RMSE)\n",
    "rmse_k = np.sqrt(mse_k)\n",
    "print(f\"RMSE: {rmse_k}\")\n",
    "\n",
    "# Real vs. Predicted Values\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(np.log10(y_test), np.log10(predict_k))\n",
    "# inserisci una linea bisettrice che rappresenta landamento ottimale dei valori\n",
    "plt.plot([y_test.min(),y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Real Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Real vs. Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67b509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf57722b2607b8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_test, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb943a1fb468b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(predict_k, bins=50)\n",
    "\n",
    "y_ravel = y_test.values.ravel()\n",
    "\n",
    "errori_list = []\n",
    "\n",
    "for a in range(0, len(y_test)):\n",
    "    errori_list.append(abs(y_ravel[a] - predict_k[a]))\n",
    "    print(f\"Valore reale: {y_ravel[a]} - Valore predetto: {predict_k[a]} \\n\"\n",
    "         f\"Errore di previsione { abs(y_ravel[a] - predict_k[a]) } \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6962845159b4bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualizzo gli errori di previsione \"non scalati\" (con i veri valori)\n",
    " \n",
    "errori_List = np.array(errori_list)\n",
    "print(\"Dimensioni di errori_array:\", errori_List.shape)\n",
    "\n",
    "# De-standardizzazione dei residui\n",
    "residui_originali = []\n",
    "\n",
    "for i in range(len(errori_List)):\n",
    "    residui_originali.append(\n",
    "        errori_List[i] * (k2_max - k2_min) + k2_min\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n---------\\nResidui originali: \\n\", residui_originali)\n",
    "# Ora residui_originali contiene i residui de-standardizzati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf596e7e59ab9",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-06-21T16:40:54.417130200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 38 folds for each of 19440 candidates, totalling 738720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x000001770D9B88C0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 640, in _next_wrapper\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 556, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 640, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 631, in input_data\n",
      "    dispatch_proxy_set_data(self.proxy, new, cat_codes, self._allow_host)\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\data.py\", line 1356, in dispatch_proxy_set_data\n",
      "    proxy._set_data_from_array(data)  # pylint: disable=W0212\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\Desktop\\Python Workspace\\FirstTryMiller\\venv\\Lib\\site-packages\\xgboost\\core.py\", line 1422, in _set_data_from_array\n",
      "    _LIB.XGProxyDMatrixSetDataDense(self.handle, _array_interface(data))\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Ottimizzazione degli iperparametri con GridSearchCV usando LOOCV\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 70, 100, 150],  # Numero di alberi nell'ensemble\n",
    "    'max_depth': [2 ,3, 5, 7],           # Profondità massima degli alberi\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],  # Tasso di apprendimento (learning rate)\n",
    "    'subsample': [0.8, 0.9, 1.0],      # Percentuale di campioni da utilizzare per ogni albero\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],  # Percentuale di colonne da utilizzare per ogni albero\n",
    "    'gamma': [0, 0.1, 0.2],            # Riduzione minima della perdita richiesta per dividere un nodo\n",
    "    'reg_alpha': [0, 0.1, 0.5],        # Termine di regolarizzazione L1 sugli pesi delle foglie\n",
    "    'reg_lambda': [0, 0.1, 0.5]        # Termine di regolarizzazione L2 sugli pesi delle foglie\n",
    "}\n",
    "\n",
    "\n",
    "# Addestramento del modello con GridSearchCV\n",
    "# LOOCV e random_state inizializzati direttamente nel GridSearchCV\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "grid_search = GridSearchCV(XGBRegressor( random_state = best_random_state ), param_grid, cv=loo, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Valutazione finale delle sole performance della LOOCV\n",
    "performance = []\n",
    "\n",
    "for train_index, test_index in loo.split(df_scaled):\n",
    "    X_train_loo, X_test_loo = df_scaled.drop('k_m2', axis=1).iloc[train_index], df_scaled.drop('k_m2', axis=1).iloc[test_index]\n",
    "    y_train_loo, y_test_loo = df_scaled['k_m2'].iloc[train_index], df_scaled['k_m2'].iloc[test_index]\n",
    "\n",
    "    best_model.fit(X_train_loo, y_train_loo)\n",
    "    y_pred_loo = best_model.predict(X_test_loo)\n",
    "    mse_loo = mean_squared_error(y_test_loo, y_pred_loo)\n",
    "    performance.append(mse_loo)\n",
    "\n",
    "media_performance = np.mean(performance)\n",
    "print(f\"Media MSE sulla LOOCV: {media_performance}\")\n",
    "\n",
    "# Plot delle prestazioni finali\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Real Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Real vs. Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ca37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot delle prestazioni finali\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Real Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Real vs. Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fe160",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_originale = []\n",
    "for i in range(len(y_test)):\n",
    "    y_test_originale.append(\n",
    "        y_test.iloc[i] * (k2_max - k2_min) + k2_min\n",
    "    )\n",
    "\n",
    "y_pred_originale = []\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred_originale.append(\n",
    "        y_pred[i] * (k2_max - k2_min) + k2_min\n",
    "    )\n",
    "\n",
    "y_pred_originale = np.array(y_pred_originale)\n",
    "y_test_originale = np.array(y_test_originale)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.xlim(0.15*10**-12, 0.8*10**-12)\n",
    "plt.ylim(0.15*10**-12, 0.8*10**-12)\n",
    "plt.scatter(y_test_originale, y_pred_originale)\n",
    "plt.plot([y_test_originale.min(), y_test_originale.max()], [y_test_originale.min(), y_test_originale.max()], 'k--', lw=2)\n",
    "plt.xlabel('Real Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Real vs. Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b2bca914b0a89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### test iperparametri più veloce...meno valori da provare....codice funzionante e veloce!!!\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "# Definisci gli iperparametri da cercare\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100,200],\n",
    "    'max_depth': [2, 3, 4, 8],\n",
    "    'max_features': [0.1, 0.5, 1,2, 5],\n",
    "    'min_samples_split': [2, 3, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'criterion': ['friedman_mse','absolute_error','squared_error']\n",
    "\n",
    "}\n",
    "\n",
    "regressor = RandomForestRegressor(random_state=49)\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "# Crea un oggetto GridSearchCV per la ricerca degli iperparametri con cross-validation\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=5, scoring='neg_mean_squared_error', verbose = 1)\n",
    "# Lista per tenere traccia del tempo di esecuzione di ciascun set di iperparametri\n",
    "execution_times = []\n",
    "# Definisci il tempo massimo di esecuzione in secondi (300 secondi = 5 minuti)\n",
    "max_execution_time = 300\n",
    "start_time = time.time()\n",
    "# Esegui la ricerca degli iperparametri\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "# Trova il miglior modello\n",
    "best_model = grid_search.best_estimator_\n",
    "# Valuta il modello sul set di test\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2_bestModel = best_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best MSE Score:\", -grid_search.best_score_)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R^2 Score:\", r2_bestModel)\n",
    "print(\"Training Time (seconds):\", training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355081690f660698",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assicurati che siano array NumPy o serie Pandas\n",
    "y_test = np.array(y_test)\n",
    "predictions_rf = np.array(y_pred)\n",
    "# Analisi degli errori\n",
    "errore = []\n",
    "for i in range(len(y_test)):\n",
    "   errore.append(y_test[i] - predictions_rf[i])\n",
    "print(errore)\n",
    "print(\"--------------------\")\n",
    "# Supponendo che errore sia la tua lista di array\n",
    "errore_concatenato = np.concatenate(errore)\n",
    "\n",
    "# Creare un DataFrame pandas con una colonna chiamata 'Errore'\n",
    "df_errore = pd.DataFrame({'Errore': errore_concatenato})\n",
    "\n",
    "# Grafico degli errori\n",
    "plt.scatter(predictions_rf, df_errore)\n",
    "plt.xlabel('Previsioni')\n",
    "plt.ylabel('Errori')\n",
    "plt.title('Analisi degli Errori (RandomForestRegressor)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e754e2deaa5bf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Codice che mi serve solo per controllare se l'allenamento procede correttamente.\n",
    "#Devo controllare che gli errori non si discostino troppo dai valori reali\n",
    "#Ora controllo dopo averlo allenato col modello migliore utilizzando gli iperparametri migliori\n",
    "\n",
    "errorilist2 = []\n",
    "\n",
    "for a in range(0, len(y_test)):\n",
    "    errorilist2.append(abs(y_ravel[a] - y_pred[a]))\n",
    "    print(f\"Valore reale: {y_ravel[a]} - Valore predetto: {y_pred[a]} \\n\"\n",
    "         f\"Errore di previsione { abs(y_ravel[a] - y_pred[a]) } \\n\")\n",
    "    \n",
    "erroriList2 = np.array(errorilist2)\n",
    "\n",
    "# De-standardizzazione dei residui\n",
    "residui_originali_2 = []\n",
    "print(y_test)\n",
    "for i in range(len(erroriList2)):\n",
    "    residui_originali_2.append(\n",
    "        erroriList2[i] * (k2_max - k2_min) + k2_min\n",
    "    )\n",
    "\n",
    "print(\"Residui originali: \\n\", residui_originali_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28a3d8371b779d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In questa sezione devo verificare se il range di errore destandardizzato è accettabile\n",
    "# L'errore può essere accettabile se non supera il range di un'ordine di grandezza\n",
    "\n",
    "sentinella = 0\n",
    "# Il rapporto che governerà questo range sarà il seguente:\n",
    "# 0.7 < (y_test[i] / residui_originali[i]) < 1.3         -->     controllo del (+/-) 30% di errore\n",
    "for i in range(len(y_test)):\n",
    "    if 1.000000000000001 > (np.log10(y_ravel[i]) / np.log10(residui_originali_2[i])) > 0.999999999999:\n",
    "        print(f\"Errore di previsione del dato {i} superiore al range ammissibile di un'ordine di grandezza\")\n",
    "        sentinella = 1\n",
    "\n",
    "if sentinella == 0: \n",
    "    print(\"Tutti gli errori rientrano nel range di accettabilità\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3136f5110d42e20",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Eseguo una cross validation per verificare se il modello è robusto con la tecnica LOOCV\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Inizializza lo schema LOOCV\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Inizializza un array per tenere traccia delle prestazioni\n",
    "performance = []\n",
    "\n",
    "# Ciclo attraverso le iterazioni della LOOCV\n",
    "for train_index, test_index in loo.split(df_scaled):\n",
    "    X_train, X_test = df_scaled.drop('k_m2', axis=1).iloc[train_index], df_scaled.drop('k_m2', axis=1).iloc[test_index]\n",
    "    y_train, y_test = df_scaled['k_m2'].iloc[train_index], df_scaled['k_m2'].iloc[test_index]\n",
    "\n",
    "    # Addestra il regressore\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Valuta le prestazioni sul set di test\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    performance.append(mse)\n",
    "\n",
    "# Media degli errori quadratici medi ottenuti in ciascuna iterazione\n",
    "media_performance = np.mean(performance)\n",
    "print(f\"Media MSE sulla LOOCV: {media_performance}\")\n",
    "\n",
    "# #Escludo i valori con la varianza maggiore di de\n",
    "# performance_senza_outlier = []\n",
    "# \n",
    "# for valore in performance:\n",
    "#     if valore <= 0.05:\n",
    "#         performance_senza_outlier.append(valore)\n",
    "\n",
    "# Plot delle prestazioni in ciascuna iterazione\n",
    "plt.plot(performance, marker='o')\n",
    "plt.xlabel('Iterazione LOOCV')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Prestazioni nella LOOCV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5254bef5be1f2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ho identificato alcune soglie con il quale è possibile visualizzare meglio le performance dell'algoritmo LOO\n",
    "# Per fare ciò però ogni volta è necessario eliminare i valori al di sopra di quelle soglie. Verranno provate multiple visualizzazione in modo da non \n",
    "# perdere nessun valore utile\n",
    "\n",
    "soglie = [0.05, 0.003, 0.0013, 0.000213, 0.00006, 0.00003]\n",
    "\n",
    "# Ciclo attraverso le soglie\n",
    "for soglia in soglie:\n",
    "    # Riinizializza l'array ad ogni iterazione\n",
    "    performance_senza_outlier = []\n",
    "\n",
    "    # Filtra gli outlier in base alla soglia corrente\n",
    "    for valore in performance:\n",
    "        if valore <= soglia:\n",
    "            performance_senza_outlier.append(valore)\n",
    "\n",
    "    # Stampa e plotta le prestazioni senza outlier\n",
    "    print(f\"Plot per la soglia {soglia}\")\n",
    "    plt.plot(performance_senza_outlier, marker='o')\n",
    "    plt.xlabel('Iterazione LOOCV')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title(f'Prestazioni nella LOOCV con soglia {soglia}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a15b66c596850a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ANALISI DEI RESIDUI\n",
    "\n",
    "#QQ plot\n",
    "from scipy import stats\n",
    "\n",
    "stats.probplot(erroriList2, plot=plt)\n",
    "plt.title('Q-Q Plot dei Residui')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# salvare il modello allenato di XGBoost\n",
    "import pickle\n",
    "\n",
    "# Salva il modello su disco\n",
    "with open('RandomForestRegressor_Permeability.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "print(\"Modello salvato come 'RandomForestRegressor_Permeability.pkl'\")\n",
    "##################################################################\n",
    "\n",
    "# Carica il modello salvato\n",
    "import pickle\n",
    "with open('RandomForestRegressor_Permeability.pkl', 'rb') as model_file:\n",
    "    loaded_model_RFR_Perm = pickle.load(model_file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "651d1353fcdc867"
  },
  {
   "cell_type": "markdown",
   "id": "9564d6a60409c6f8",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
